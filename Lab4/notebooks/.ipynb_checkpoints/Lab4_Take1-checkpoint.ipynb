{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "import requests as r\n",
    "\n",
    "#import geopandas as gp\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date, datetime, timedelta\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the ETL: access, download to csv, reup as pandas dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Build the ETL, by using all stations and specifying the time\n",
    "#use requests.get to get the data, save to csv\n",
    "#bring the csv into pandas df to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://ndawn.ndsu.nodak.edu/get-table.html\"\n",
    "station = \"?station=\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, timedelta\n",
    "\n",
    "current_date = date.today().isoformat()   \n",
    "days_before = (date.today()-timedelta(days=30)).isoformat()\n",
    "days_after = (date.today()+timedelta(days=30)).isoformat()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"https://ndawn.ndsu.nodak.edu/get-table.html?station=78&station=111&station=98&station=142&station=138&station=9&station=10&station=118&station=56&station=11&station=12&station=58&station=13&station=84&station=55&station=7&station=87&station=14&station=15&station=96&station=16&station=137&station=124&station=17&station=85&station=140&station=134&station=18&station=136&station=65&station=104&station=99&station=19&station=129&station=20&station=101&station=81&station=21&station=97&station=22&station=75&station=2&station=139&station=23&station=62&station=86&station=24&station=89&station=126&station=93&station=90&station=25&station=83&station=107&station=77&station=26&station=70&station=127&station=27&station=132&station=28&station=29&station=30&station=31&station=102&station=32&station=119&station=4&station=80&station=33&station=59&station=105&station=82&station=34&station=72&station=135&station=35&station=76&station=120&station=141&station=109&station=36&station=79&station=71&station=37&station=38&station=39&station=130&station=73&station=40&station=41&station=54&station=69&station=113&station=128&station=42&station=43&station=103&station=116&station=88&station=114&station=3&station=64&station=115&station=67&station=44&station=133&station=106&station=100&station=121&station=45&station=46&station=61&station=66&station=74&station=60&station=125&station=8&station=47&station=122&station=108&station=5&station=48&station=68&station=49&station=50&station=91&station=117&station=63&station=51&station=6&station=52&station=92&station=112&station=131&station=123&station=95&station=53&station=57&station=110&variable=ddavt&year=2021&ttype=daily\"\n",
    "#base = \"https://ndawn.ndsu.nodak.edu/get-table.html?station=78&variable=ddavt&year=2021&ttype=daily\"\n",
    "#startDate='YYYY-MM-DD'\n",
    "#endDate='YYYY-MM-DD'\n",
    "\n",
    "       \n",
    "#startDateCheck = date.fromisoformat(startDate)\n",
    "#endDateCheck = date.fromisoformat(endDate)\n",
    "\n",
    "endDate = date.today().isoformat()\n",
    "beginDate = (date.today()-timedelta(days=30)).isoformat()\n",
    "\n",
    "date_var = \"&quick_pick=&begin_date=\"\n",
    "#+ beginDate + \"&end_date=\" + endDate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ndawn.ndsu.nodak.edu/get-table.html?station=78&variable=ddavt&year=2021&ttype=daily&quick_pick=&begin_date=2021-03-05&end_date=2021-04-04\n"
     ]
    }
   ],
   "source": [
    "download = str(base + date_var + beginDate + \"&end_date=\" + endDate)\n",
    "#download = str(base + date_var)\n",
    "print(download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndawndata = r.get(download)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You are here: CSV is garbage so it won't load into Pandas dataframe\n",
    "Maybe: read directly from URL?\n",
    "Otherwise, back to the drawing board on reading the r.get into a csv\n",
    "https://towardsdatascience.com/all-the-pandas-read-csv-you-should-know-to-speed-up-your-data-analysis-1e16fe1039f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17294"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"ndawnData.csv\",\"wb\").write(ndawndata.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 7: expected 1 fields, saw 7\\nSkipping line 8: expected 1 fields, saw 3\\nSkipping line 9: expected 1 fields, saw 2\\nSkipping line 10: expected 1 fields, saw 5\\nSkipping line 11: expected 1 fields, saw 3\\nSkipping line 12: expected 1 fields, saw 2\\nSkipping line 41: expected 1 fields, saw 3\\nSkipping line 90: expected 1 fields, saw 2\\nSkipping line 97: expected 1 fields, saw 2\\nSkipping line 103: expected 1 fields, saw 2\\nSkipping line 104: expected 1 fields, saw 2\\nSkipping line 110: expected 1 fields, saw 2\\nSkipping line 118: expected 1 fields, saw 2\\nSkipping line 122: expected 1 fields, saw 2\\nSkipping line 127: expected 1 fields, saw 2\\nSkipping line 135: expected 1 fields, saw 2\\nSkipping line 136: expected 1 fields, saw 2\\nSkipping line 142: expected 1 fields, saw 2\\nSkipping line 151: expected 1 fields, saw 2\\nSkipping line 152: expected 1 fields, saw 2\\nSkipping line 157: expected 1 fields, saw 2\\nSkipping line 163: expected 1 fields, saw 2\\nSkipping line 168: expected 1 fields, saw 2\\nSkipping line 180: expected 1 fields, saw 2\\nSkipping line 181: expected 1 fields, saw 2\\nSkipping line 183: expected 1 fields, saw 2\\nSkipping line 184: expected 1 fields, saw 2\\nSkipping line 186: expected 1 fields, saw 2\\nSkipping line 191: expected 1 fields, saw 2\\nSkipping line 192: expected 1 fields, saw 2\\nSkipping line 195: expected 1 fields, saw 2\\nSkipping line 198: expected 1 fields, saw 2\\nSkipping line 200: expected 1 fields, saw 2\\nSkipping line 202: expected 1 fields, saw 2\\nSkipping line 204: expected 1 fields, saw 2\\nSkipping line 208: expected 1 fields, saw 2\\nSkipping line 209: expected 1 fields, saw 2\\nSkipping line 211: expected 1 fields, saw 2\\nSkipping line 213: expected 1 fields, saw 2\\nSkipping line 216: expected 1 fields, saw 2\\nSkipping line 217: expected 1 fields, saw 2\\n'\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(download, index_col=False, encoding='iso-8859-1', nrows=1000,\n",
    "                        warn_bad_lines=True, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;!DOCTYPE html&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;html lang=\"en\"&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;head&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;title&gt;NDAWN Tables - Daily Weather Data&lt;/ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;meta http-equiv=\"Content-Type\" content=\"tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;script&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     <!DOCTYPE html>\n",
       "0                                   <html lang=\"en\">\n",
       "1                                             <head>\n",
       "2    <title>NDAWN Tables - Daily Weather Data</ti...\n",
       "3    <meta http-equiv=\"Content-Type\" content=\"tex...\n",
       "4                                           <script>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 7, saw 7\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1318af3d4a2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mndawndata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\celia\\Documents\\GitHub\\GIS5572\\Lab4\\ndawnData.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1184\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\ArcGIS\\Pro\\bin\\Python\\envs\\arcgispro-py3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2143\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2145\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2146\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 7, saw 7\n"
     ]
    }
   ],
   "source": [
    "ndawndata = pd.read_csv(r\"C:\\Users\\celia\\Documents\\GitHub\\GIS5572\\Lab4\\ndawnData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndawndata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find averages, map all stations and averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#calc row of average for each station\n",
    "#geolocate the stations??\n",
    "#map stations + averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleRequest = ndawn_request(startDate='2020-06-23', endDate='2020-06-28', ontology=['Air Pressure', 'Relative Humidity', 'Soil Temperature', 'Wind Direction', 'Wind Speed'], location=['Mavie', 'Ottertail', 'Perham', 'Perley'])\n",
    "ndawnDF = exampleRequest.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ndawn_request:\n",
    "\n",
    "    def __init__(self, startDate='YYYY-MM-DD', endDate='YYYY-MM-DD', ontology = None, location = None, save = False):\n",
    "\n",
    "        self.start = startDate\n",
    "\n",
    "        self.end = endDate\n",
    "\n",
    "        # List of ontology terms, and their URL codes to build request URL\n",
    "        self.ontology = {\n",
    "            'Air Temperature': ['variable=hdt', 'variable=hdt9'],\n",
    "           \n",
    "        }\n",
    "        # Concatenate the ontology keys into a list for exception printout later\n",
    "        ontologiesErrorMessage = '\\n'.join(list(self.ontology.keys()))\n",
    "\n",
    "        # List of stations, and URL codes to build request URL\n",
    "        self.stations = {\n",
    "            'Ada': 78,\n",
    "            'Becker': 118,\n",
    "            'Campbell': 87,\n",
    "           \n",
    "        }\n",
    "        # Concatenate station names into a list for exception printout later\n",
    "        stationsErrorMessage = '\\n'.join(list(self.stations.keys()))\n",
    "\n",
    "        self.save = save\n",
    "\n",
    "        # This checks the start and end dates supplied to make sure they are valid\n",
    "        # Start by converting dates into iso format\n",
    "        startDateCheck = date.fromisoformat(startDate)\n",
    "        endDateCheck = date.fromisoformat(endDate)\n",
    "        # If start date is after end date, raise exception\n",
    "        if startDateCheck > endDateCheck:\n",
    "            raise Exception('End date cannot be before start date')\n",
    "\n",
    "    def get_data(self):\n",
    "        \n",
    "        # Construct API call for the request\n",
    "        baseURL = 'https://ndawn.ndsu.nodak.edu/table.csv?'\n",
    "        stations = '&'.join(self.activeStations)\n",
    "        measurements = '&'.join(self.activeMeasures)\n",
    "        options = '&ttype=hourly&quick_pick=&begin_date=' + self.start + '&end_date=' + self.end\n",
    "        finalURL = str(baseURL + stations + '&' + measurements + options)\n",
    "        \n",
    "        # Request page\n",
    "        page = requests.get(finalURL)\n",
    "        # If status code not 200, raise exception\n",
    "        if page.status_code != 200:\n",
    "            raise Exception('URL request status not 200. Status code = ' + page.status_code)\n",
    "\n",
    "        print('Request successful')\n",
    "\n",
    "        # Convert csv data to string\n",
    "        content = str(page.content)\n",
    "        # Remove large, unnecessary header\n",
    "        trimContent = content[content.find('Station'):len(content)]\n",
    "        # Replace newline/return with string literal newline\n",
    "        formatContent = trimContent.replace('\\\\r\\\\n', '\\n')\n",
    "        # Convert content to file object\n",
    "        contentFile = StringIO(formatContent)\n",
    "\n",
    "        # Read content into pandas dataframe. Second header row contains units\n",
    "        ndawnData = pd.read_csv(contentFile, header = [0, 1])\n",
    "        \n",
    "        # Concatenate headers to include units\n",
    "        # Assign column list to object\n",
    "        columnHeaders = list(ndawnData.columns)\n",
    "        # List of new headers\n",
    "        newHeaderList = []\n",
    "        # Iterate through column names\n",
    "        for number in range(0, len(columnHeaders)):\n",
    "            # If no unit, keep header unchanged, pass into new list\n",
    "            if 'Unnamed' in columnHeaders[number][1]:\n",
    "                newHeaderList.append(columnHeaders[number][0])\n",
    "            # If unit exists, concatenate header and unit, pass into new list\n",
    "            else:\n",
    "                newHeader = columnHeaders[number][0] + ' (' + columnHeaders[number][1] + ') '\n",
    "                newHeaderList.append(newHeader)\n",
    "        # Assign new column names\n",
    "        ndawnData.columns = newHeaderList\n",
    "\n",
    "        # Create single column for datetime\n",
    "        ndawnData['Date'] = pd.to_datetime(ndawnData[['Year', 'Month', 'Day']])\n",
    "        \n",
    "        # Save to csv if save option selected\n",
    "        if self.save:\n",
    "            ndawnData.to_csv('ndawnData.csv', index=False)\n",
    "\n",
    "        return ndawnData\n",
    "\n",
    "'''\n",
    "# Example syntax:\n",
    "exampleRequest = ndawn_request(startDate='2020-06-23', endDate='2020-06-28', ontology=['Air Pressure', 'Relative Humidity', 'Soil Temperature', 'Wind Direction', 'Wind Speed'], location=['Mavie', 'Ottertail', 'Perham', 'Perley'])\n",
    "ndawnDF = exampleRequest.get_data()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
